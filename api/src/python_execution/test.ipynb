{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "sys.path.insert(0, \"/Users/robertlukoshko/Programming/quanto/lablabai-hackathon/api/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://eiruqjgfkgoknuhihfha.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImVpcnVxamdma2dva251aGloZmhhIiwicm9sZSI6ImFub24iLCJpYXQiOjE2OTI0MzQxNTcsImV4cCI6MjAwODAxMDE1N30.HKZHbuiB2r8NN367J0LkD2UgwhaqJS2f0Ux9ezCFETA\"\n",
    "supabase: Client = create_client(url, key)\n",
    "table = supabase.table(\"db_steps\")\n",
    "bucket = supabase.storage.from_('bucket_steps')\n",
    "\n",
    "from typing import *\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "class Task:\n",
    "    task_id: int = None\n",
    "    task_name: str  # human-readable\n",
    "    user_id: str  # just the email for now\n",
    "    max_step_count: int\n",
    "    def __init__(self, user_id: str, task_id: int | None = None, task_name: str | None = None,\n",
    "                 initial_df: DataFrame | None = None, initial_df_frontend: DataFrame | None = None):\n",
    "        \"\"\" Create a new task for a new initial_df DataFrame or retrieve an existing task with task_id \"\"\"\n",
    "        self.user_id = user_id\n",
    "        self.task_id = task_id\n",
    "        self.task_name = task_name\n",
    "\n",
    "        if self.task_id is None:\n",
    "            # create a new task\n",
    "            task_ids: List = table.select('task_id').execute().data\n",
    "            max_id = max([id['task_id'] for id in task_ids]) if not task_ids == [] else 0\n",
    "            self.task_id = max_id + 1\n",
    "            self.max_step_count = 0\n",
    "\n",
    "            if initial_df is None:\n",
    "                raise ValueError('initial_df must be provided when creating a new task, i.e. when task_id is None')\n",
    "            if initial_df_frontend is None:\n",
    "                initial_df_frontend = initial_df\n",
    "            self.upload_new_step('', 'Initial DataFrame', initial_df, initial_df_frontend)\n",
    "        else:\n",
    "            # find max step id within an existing task\n",
    "            step_counts: List = table.select('task_id, step_count').eq('task_id', self.task_id).execute().data\n",
    "            self.max_step_count = max([int(c['step_count']) for c in step_counts])\n",
    "\n",
    "    def upload_new_step(self, transformation: str, explanation: str, df_after: DataFrame, df_frontend: DataFrame):\n",
    "        \"\"\" Upload a new step in the task to the DB \"\"\"\n",
    "        self.max_step_count += 1\n",
    "        step_id = str(self.task_id) + '_' + str(self.max_step_count)\n",
    "\n",
    "        # convert dataframes to csv\n",
    "        os.makedirs('temp', exist_ok=True)\n",
    "        df_after.to_csv('temp/df.csv', index=False)\n",
    "        with open('temp/df.csv', 'rb') as f:\n",
    "            filepath = f'{self.user_id}/df_after_{step_id}.csv'\n",
    "            bucket.upload(filepath, f)\n",
    "            df_after_url = bucket.get_public_url(filepath)\n",
    "        df_frontend.to_csv('temp/df.csv', index=False)\n",
    "        with open('temp/df.csv', 'rb') as f:\n",
    "            filepath = f'{self.user_id}/df_frontend_{step_id}.csv'\n",
    "            bucket.upload(filepath, f)\n",
    "            df_frontend_url = bucket.get_public_url(filepath)\n",
    "        os.remove('temp/df.csv')\n",
    "\n",
    "        table.insert({\n",
    "            'step_id': step_id,\n",
    "            'task_id': self.task_id,\n",
    "            'task_name': self.task_name,\n",
    "            'step_count': self.max_step_count,\n",
    "            'user_id': self.user_id,\n",
    "            'transformation': transformation,\n",
    "            'explanation': explanation,\n",
    "            'df_after': df_after_url,\n",
    "            'df_frontend': df_frontend_url\n",
    "        }).execute()\n",
    "    \n",
    "    def get_latest_df(self) -> DataFrame:\n",
    "        \"\"\" Get the DataFrame corresponding to the latest step in the task \"\"\"\n",
    "        url = table.select('df_after').eq('task_id', self.task_id).eq('step_count', self.max_step_count).execute().data[0]['df_after']\n",
    "        csv_string = requests.get(url).text\n",
    "        df: DataFrame = pd.read_csv(StringIO(csv_string))\n",
    "        return df\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     my_df = DataFrame({'a': [1, 2, 3]})\n",
    "#     task = Task(user_id='alex@example.com', task_name=\"Alex's Task\", initial_df=my_df, initial_df_frontend=my_df)\n",
    "#     task.upload_new_step('lambda x: x', 'Alex transformation 1 - no change', my_df, my_df)\n",
    "\n",
    "#     task = Task(user_id='nico@example.com', task_name=\"Nico's Task\", initial_df=my_df, initial_df_frontend=my_df)\n",
    "#     # task = Task(user_id='nico@example.com', task_name='some task')\n",
    "#     task.upload_new_step('lambda x: x', 'Nico transformation 1 - no change', my_df, my_df)\n",
    "#     task.upload_new_step('lambda x: x', 'Nico transformation 2 - no change', my_df, my_df)\n",
    "#     task.upload_new_step('lambda x: x', 'Nico transformation 3 - no change', my_df, my_df)\n",
    "#     # print(task.task_id, task.user_id, task.max_step_count)\n",
    "\n",
    "#     # with open('test_csv/test.csv', 'rb') as f:\n",
    "#     #     res = bucket.upload('test3.csv', f)\n",
    "#     #     print(res)\n",
    "#     #     print(bucket.get_public_url('test1.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"alex@example.com\"\n",
    "task_id = \"2\"\n",
    "task_name = \"Alex's Task\"\n",
    "# df dublicate first two rows\n",
    "code = \"\"\"df = pd.concat([df, df.iloc[:2]], ignore_index=True)\n",
    "import numpy as np\n",
    "df['C'] = np.random.rand(len(df))\n",
    "df = df.sort_values('C')\n",
    "\"\"\"\n",
    "explanation = \"explanation\"\n",
    "# encode sting for the url \n",
    "# code = urllib.parse.quote(code)\n",
    "explanation = urllib.parse.quote(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(\n",
    "        user_id=user_id,\n",
    "        task_id=task_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = task.get_latest_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df, df.iloc[:2]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  3\n",
       "1  2  4\n",
       "2  1  3\n",
       "3  2  4"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the query string\n",
    "# code = urllib.parse.quote_plus(\"\"\"df = pd.concat([df, df.iloc[:2]], ignore_index=True)\n",
    "code = urllib.parse.quote_plus(\"\"\"df = df.iloc[:2]\n",
    "import numpy as np\n",
    "df['C'] = np.random.rand(len(df))\n",
    "df = df.sort_values('C')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    f'http://0.0.0.0:80/execute?user_id={user_id}&task_id={task_id}&task_name={task_name}&code={code}&explanation={explanation}'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/robertlukoshko/Programming/archive/DataWork/notebooks/archive/Customer_Behaviour.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summary(summary:dict):\n",
    "    messages = [\n",
    "        {\n",
    "        \"role\": \"system\", \"content\": \"DATAFRAME sample and some stats:\" +json.dumps(summary)\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\", \"content\": \"\"\"\n",
    "reason about what do you notice in the databaframe as the best kaggle competition master doing data cleaning\n",
    "\n",
    "return output in this form\n",
    "1. reasoning. some dependencies, mistakes, something unstable which can influence data cleaning and etc.\n",
    "2. brief compact structed way of this output. clean table\n",
    "general  to skip: \n",
    "-skip ID\n",
    "-user name\n",
    "-memory\n",
    "\n",
    "be short and very precise. pass all information in a compact words only very techincal person can understand.\n",
    "at the end leave a small sample of the data\n",
    "\"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model='gpt-4',\n",
    "            messages=messages,\n",
    "            max_tokens=500,\n",
    "            )\n",
    "    return response.choices[0].message.content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_summary(df, n=10):\n",
    "    \"\"\"\n",
    "    Provides the first few rows of the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - n: Number of rows to return\n",
    "\n",
    "    Returns:\n",
    "    - Instructions what transformations to do in general based on a view of the data.\n",
    "    \"\"\"\n",
    "    # TODO: use this function as input to make_tool(), possibly experiment with adding some more stats to the prompt\n",
    "    head = df.head(n)\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    numerical = df.describe()\n",
    "    num_rows = len(df)\n",
    "    num_cols = len(df.columns)\n",
    "    unique_values = df.nunique().to_string()\n",
    "    value_counts = df.apply(lambda x: x.value_counts().index[0]).to_string()\n",
    "\n",
    "    summary = {\n",
    "        \"Description of the Numerical Columns\": numerical.to_string(),\n",
    "        \"Head of the DataFrame\": head.to_string(),\n",
    "        \"Column Infos\": s,\n",
    "        \"Missing values stat\": df.isnull().sum().to_string(),\n",
    "        \"Data Types\": df.dtypes.to_string(),\n",
    "        \"Number of Rows\": num_rows,\n",
    "        \"Number of Columns\": num_cols,\n",
    "        \"Unique Values\": unique_values,\n",
    "        \"Value Counts\": value_counts,\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reasoning:\n",
      "    - The dataset is relatively clean without missing values across all columns.\n",
      "    - The 'User ID' column may be ignored considering IDs usually bear no correlation with the target variable.\n",
      "    - Data types are generally assigned correctly, the categorical variable 'Gender' is correctly assigned as 'object'.\n",
      "    - The 'Purchased' column appears to be a binary classification target, with balance leaning towards '0', which might lead to class imbalance.\n",
      "    - The 'Age' and 'EstimatedSalary' are numerical variables and might need to be standardized as their scales are significantly different which can affect certain Machine Learning models.\n",
      "    - Uneven count values reflect that 'EstimatedSalary' and 'Age' are continuous variables, whereas 'Gender' and 'Purchased' are categorical. \n",
      "\n",
      "2. Compact Structure:\n",
      "    - Drop 'User ID' column.\n",
      "    - Check 'Purchased' column for class imbalance, handle if necessary.\n",
      "    - Standardize/Normalize 'Age' and 'EstimatedSalary'.\n",
      "    - Convert 'Gender' from categorical to numerical (Encoding).\n",
      "    - Check for outliers in 'Age' and 'EstimatedSalary' and handle if necessary.\n",
      "\n",
      "Final Data Sample:\n",
      "\n",
      "   | Gender | Age | EstimatedSalary | Purchased\n",
      "---|---     |---  |---              |---  \n",
      "0  | Male   | 19  | 19000           | 0\n",
      "1  | Male   | 35  | 20000           | 0\n",
      "2  | Female | 26  | 43000           | 0\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_summary(\n",
    "    general_summary(\n",
    "        df,\n",
    "        )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('/Users/robertlukoshko/Programming/quanto/lablabai-hackathon/test_csv/Financials.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.columns = f.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('/Users/robertlukoshko/Programming/quanto/lablabai-hackathon/test_csv/Financials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import DataFrame\n",
    "import urllib\n",
    "from tenacity import retry, stop_after_attempt, retry_if_result, wait_fixed\n",
    "import openai\n",
    "import re\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "\n",
    "EXECUTOR_ENDPOINT = 'https://executor-dnrxaaj6sq-lm.a.run.app/execute'\n",
    "MAX_NUM_STEPS = 8\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "REGENERATE_TO_FIX = \"\"\"\n",
    "Here is the current code\n",
    "{code}\n",
    "Here is the error message\n",
    "{error_msg}\n",
    "Here is the explanation\n",
    "{explanation}\n",
    "Fix the code to make it work. avoid any other possible mistakes in this area. be smart\n",
    "act as the best python developer\n",
    "```python\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regenrate_to_fix(code, error_msg, explanation):\n",
    "    \"\"\"\n",
    "    Regenerate the code if there is an error in execution.\n",
    "    \"\"\"\n",
    "    prompt = REGENERATE_TO_FIX.format(code=code, error_msg=error_msg, explanation=explanation)\n",
    "    params = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    for retry in range(3):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(**params)[\"choices\"][0][\"message\"][\"content\"]\n",
    "            new_code = \"\\n\\n\".join(re.findall(r\"```python\\n(.*?)```\", response, re.DOTALL))\n",
    "            return new_code\n",
    "        except Exception as e:\n",
    "            print(f\"Error in regenerating code: {str(e)}\")\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nprint(\"hello world\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regenrate_to_fix(\n",
    "    '''import pandas as pd\n",
    "print*(\"hello world\")''', \n",
    "\"TypeError: can't multiply sequence by non-int of type 'builtin_function_or_method'\",\n",
    "\"type print hello world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39;49m\u001b[39m*\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mhello world\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "print*(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
